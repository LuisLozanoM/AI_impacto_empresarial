{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32a07df4",
   "metadata": {},
   "source": [
    "# üìö Student Setup Instructions\n",
    "\n",
    "## üéØ What This Notebook Does\n",
    "This notebook teaches you how to build an AI agent using **LangGraph** with **100% local models** (no API keys required). The agent can use tools to perform calculations.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Prerequisites & Setup (DO THIS FIRST!)\n",
    "\n",
    "### Step 1: Install Ollama\n",
    "\n",
    "**Windows:**\n",
    "```powershell\n",
    "winget install Ollama.Ollama\n",
    "```\n",
    "\n",
    "**Mac:**\n",
    "```bash\n",
    "brew install ollama\n",
    "```\n",
    "\n",
    "**Linux:**\n",
    "```bash\n",
    "curl -fsSL https://ollama.ai/install.sh | sh\n",
    "```\n",
    "\n",
    "### Step 2: Start Ollama Service\n",
    "\n",
    "**After installation, restart your terminal/VS Code**, then:\n",
    "\n",
    "**Windows (PowerShell):**\n",
    "```powershell\n",
    "Start-Process \"$env:LOCALAPPDATA\\Programs\\Ollama\\ollama.exe\" -ArgumentList \"serve\" -WindowStyle Hidden\n",
    "```\n",
    "\n",
    "**Mac/Linux:**\n",
    "```bash\n",
    "ollama serve &\n",
    "```\n",
    "\n",
    "### Step 3: Download the AI Model\n",
    "\n",
    "In a **new terminal**, run:\n",
    "```bash\n",
    "ollama pull llama3.2:1b\n",
    "```\n",
    "\n",
    "‚è±Ô∏è **Wait for download to complete** (~1.3GB, takes 5-15 minutes depending on your internet speed)\n",
    "\n",
    "You should see: `success` when complete.\n",
    "\n",
    "### Step 4: Install Python Dependencies\n",
    "\n",
    "Make sure you have these packages installed:\n",
    "\n",
    "```bash\n",
    "pip install langgraph langchain-ollama langchain-core langchain-community typing-extensions\n",
    "```\n",
    "\n",
    "### Step 5: Verify Setup\n",
    "\n",
    "Run cell 2 below to verify everything is ready!\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Once Setup is Complete:\n",
    "\n",
    "1. **Select your Python environment** (kernel) in VS Code\n",
    "2. **Run all cells** sequentially (or use \"Run All\")\n",
    "3. **Observe** how the agent uses tools to solve math problems\n",
    "\n",
    "---\n",
    "\n",
    "## üÜò Troubleshooting\n",
    "\n",
    "### \"Model not found\" error?\n",
    "- Make sure `ollama pull llama3.2:1b` completed successfully\n",
    "- Check with: `ollama list` (you should see llama3.2:1b in the list)\n",
    "\n",
    "### \"Connection refused\" error?\n",
    "- Ollama service isn't running\n",
    "- Restart it with the command in Step 2\n",
    "\n",
    "### Import errors?\n",
    "- Install missing packages: `pip install <package-name>`\n",
    "- Make sure you selected the correct Python environment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337c3e03",
   "metadata": {},
   "source": [
    "## ‚úÖ Ready to Learn!\n",
    "\n",
    "If the verification cell above shows **SUCCESS**, you're ready to go!\n",
    "\n",
    "### What You'll Learn:\n",
    "1. How to define AI tools (functions the AI can use)\n",
    "2. How to create a state machine for your agent\n",
    "3. How to build an agent that makes decisions\n",
    "4. How to use LangGraph to orchestrate everything\n",
    "\n",
    "### Tips for Students:\n",
    "- üìñ **Read the markdown cells** - they explain what each step does\n",
    "- üèÉ **Run cells sequentially** - each cell builds on the previous one\n",
    "- \udd0d **Examine the output** - see how the agent thinks and acts\n",
    "- üß™ **Experiment** - try changing the test questions in the final cells!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9647072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Ollama not found. Please check the installation.\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# VERIFICATION CELL - Run this first!\n",
    "# ========================================\n",
    "# This cell checks if Ollama and the model are properly set up\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "print(\"üîç Checking setup...\\n\")\n",
    "\n",
    "try:\n",
    "    # Try to find Ollama\n",
    "    if os.name == 'nt':  # Windows\n",
    "        ollama_path = os.path.expandvars(r\"$env:LOCALAPPDATA\\Programs\\Ollama\\ollama.exe\")\n",
    "        if not os.path.exists(ollama_path):\n",
    "            ollama_path = \"ollama\"\n",
    "    else:  # Mac/Linux\n",
    "        ollama_path = \"ollama\"\n",
    "    \n",
    "    # Check available models\n",
    "    result = subprocess.run(\n",
    "        [ollama_path, \"list\"],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=5\n",
    "    )\n",
    "    \n",
    "    print(\"üìã Available Ollama models:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(result.stdout)\n",
    "    \n",
    "    # Check if our model is available\n",
    "    if \"llama3.2:1b\" in result.stdout or \"llama3.2\" in result.stdout:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"‚úÖ SUCCESS! Setup is complete!\")\n",
    "        print(\"=\"*50)\n",
    "        print(\"\\nüéâ You can now run all cells in this notebook.\")\n",
    "        print(\"üí° Tip: Use 'Run All' or execute cells one by one with Shift+Enter\\n\")\n",
    "    else:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"‚ùå Model NOT found!\")\n",
    "        print(\"=\"*50)\n",
    "        print(\"\\n‚ö†Ô∏è  The Llama 3.2 1B model is not installed.\")\n",
    "        print(\"\\nüì• To install, run this in a terminal:\")\n",
    "        print(\"   ollama pull llama3.2:1b\")\n",
    "        print(\"\\n‚è±Ô∏è  Wait for 'success' message, then re-run this cell.\\n\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Ollama not found!\")\n",
    "    print(\"\\nüì• Please install Ollama first:\")\n",
    "    print(\"   Windows: winget install Ollama.Ollama\")\n",
    "    print(\"   Mac:     brew install ollama\")\n",
    "    print(\"   Linux:   curl -fsSL https://ollama.ai/install.sh | sh\")\n",
    "    print(\"\\nüîÑ Then restart VS Code and run this cell again.\\n\")\n",
    "    \n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"‚ö†Ô∏è  Ollama service is not responding.\")\n",
    "    print(\"\\nüöÄ Start the Ollama service:\")\n",
    "    print(\"   Windows: Start-Process \\\"$env:LOCALAPPDATA\\\\Programs\\\\Ollama\\\\ollama.exe\\\" -ArgumentList \\\"serve\\\" -WindowStyle Hidden\")\n",
    "    print(\"   Mac/Linux: ollama serve &\")\n",
    "    print(\"\\nüîÑ Then re-run this cell.\\n\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Unexpected error: {e}\")\n",
    "    print(\"\\nüí° Try these steps:\")\n",
    "    print(\"   1. Make sure Ollama is installed\")\n",
    "    print(\"   2. Start the Ollama service\")\n",
    "    print(\"   3. Run: ollama pull llama3.2:1b\")\n",
    "    print(\"   4. Re-run this cell\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff97c400",
   "metadata": {},
   "source": [
    "# LangGraph Quickstart - Local Models Edition\n",
    "\n",
    "This notebook replicates the official LangGraph quickstart tutorial using **local models via Ollama**.\n",
    "\n",
    "## Model Being Used\n",
    "- **Llama 3.2 1B** via Ollama (fast, lightweight, supports tool calling)\n",
    "\n",
    "## Prerequisites\n",
    "- ‚úÖ Ollama installed and running\n",
    "- ‚úÖ Llama 3.2 1B model downloaded\n",
    "- ‚úÖ LangGraph and dependencies installed\n",
    "\n",
    "## What This Tutorial Covers\n",
    "1. Define tools and model (using Ollama instead of Anthropic)\n",
    "2. Define state for the agent\n",
    "3. Define model node\n",
    "4. Define tool node\n",
    "5. Define routing logic\n",
    "6. Build and compile the agent\n",
    "7. Run the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815615e5",
   "metadata": {},
   "source": [
    "## Step 1: Define Tools and Model\n",
    "\n",
    "We'll use **Llama 3.2 1B via Ollama** (local model with tool calling support) instead of Claude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "583e9218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded: Llama 3.2 1B (local via Ollama)\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Use local Llama 3.2 1B model via Ollama (smaller, faster)\n",
    "model = ChatOllama(\n",
    "    model=\"llama3.2:1b\",  # Local model with tool calling support\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model loaded: Llama 3.2 1B (local via Ollama)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69f57b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tools defined: add, multiply, divide\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# DEFINE TOOLS\n",
    "# ========================================\n",
    "# Tools are Python functions that the AI can call.\n",
    "# The @tool decorator makes them available to the LLM.\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply `a` and `b`.\n",
    "\n",
    "    Args:\n",
    "        a: First int\n",
    "        b: Second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds `a` and `b`.\n",
    "\n",
    "    Args:\n",
    "        a: First int\n",
    "        b: Second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide `a` and `b`.\n",
    "\n",
    "    Args:\n",
    "        a: First int\n",
    "        b: Second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# BIND TOOLS TO MODEL\n",
    "# ========================================\n",
    "# This tells the model which tools are available.\n",
    "# The model can now decide when to use these tools.\n",
    "\n",
    "tools = [add, multiply, divide]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "print(f\"‚úÖ Tools defined: {', '.join([t.name for t in tools])}\")\n",
    "print(f\"üìù The AI can now use these {len(tools)} tools to solve problems!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb39543",
   "metadata": {},
   "source": [
    "## Step 2: Define State\n",
    "\n",
    "The graph's state stores messages and tracks the number of LLM calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff327fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ State defined\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AnyMessage\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "import operator\n",
    "\n",
    "# ========================================\n",
    "# STATE DEFINITION\n",
    "# ========================================\n",
    "# State stores all information as the agent runs.\n",
    "# Think of it like the agent's \"memory\" during execution.\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    # messages: The conversation history (user messages, AI responses, tool results)\n",
    "    # operator.add means new messages are APPENDED, not replaced\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "    \n",
    "    # llm_calls: Counts how many times we called the LLM (for debugging/monitoring)\n",
    "    llm_calls: int\n",
    "\n",
    "print(\"‚úÖ State defined\")\n",
    "print(\"üìù State will track: conversation messages + LLM call count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aad139f",
   "metadata": {},
   "source": [
    "## Step 3: Define Model Node\n",
    "\n",
    "The model node calls the LLM and decides whether to use a tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd2640d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model node defined\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "# ========================================\n",
    "# MODEL NODE (The \"Brain\")\n",
    "# ========================================\n",
    "# This node calls the LLM to decide what to do.\n",
    "# The LLM can either:\n",
    "#   1. Call a tool (if it needs to perform an action)\n",
    "#   2. Respond directly (if it has enough information)\n",
    "\n",
    "def llm_call(state: dict):\n",
    "    \"\"\"LLM decides whether to call a tool or not\"\"\"\n",
    "    \n",
    "    # Add system message to give the AI its role/instructions\n",
    "    system_msg = SystemMessage(\n",
    "        content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\"\n",
    "    )\n",
    "    \n",
    "    # Call the model with system message + conversation history\n",
    "    response = model_with_tools.invoke([system_msg] + state[\"messages\"])\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [response],  # Add AI response to conversation\n",
    "        \"llm_calls\": state.get('llm_calls', 0) + 1  # Increment counter\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Model node defined\")\n",
    "print(\"üìù This node lets the AI analyze the request and decide actions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e191dbd",
   "metadata": {},
   "source": [
    "## Step 4: Define Tool Node\n",
    "\n",
    "The tool node executes the tools and returns results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3375a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tool node defined\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "# ========================================\n",
    "# TOOL NODE (The \"Hands\")\n",
    "# ========================================\n",
    "# This node executes the tools that the LLM requested.\n",
    "# It takes the tool calls from the AI and actually runs them.\n",
    "\n",
    "def tool_node(state: dict):\n",
    "    \"\"\"Performs the tool call\"\"\"\n",
    "    \n",
    "    result = []\n",
    "    last_message = state[\"messages\"][-1]  # Get the last AI message\n",
    "    \n",
    "    # Loop through each tool call the AI requested\n",
    "    for tool_call in last_message.tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]  # Get the actual tool function\n",
    "        observation = tool.invoke(tool_call[\"args\"])  # Execute the tool\n",
    "        \n",
    "        # Create a message with the tool result\n",
    "        result.append(ToolMessage(\n",
    "            content=str(observation), \n",
    "            tool_call_id=tool_call[\"id\"]\n",
    "        ))\n",
    "    \n",
    "    return {\"messages\": result}\n",
    "\n",
    "print(\"‚úÖ Tool node defined\")\n",
    "print(\"üìù This node executes the actual calculations when the AI requests them\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e7324a",
   "metadata": {},
   "source": [
    "## Step 5: Define Routing Logic\n",
    "\n",
    "The conditional edge decides whether to continue to tools or end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088c3647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Routing logic defined\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# ========================================\n",
    "# ROUTING LOGIC (The \"Decision Maker\")\n",
    "# ========================================\n",
    "# This function decides the next step in the workflow.\n",
    "# It's like a traffic controller directing the flow.\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"tool_node\", END]:\n",
    "    \"\"\"Decide if we should continue the loop or stop based upon whether the LLM made a tool call\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # Check if the AI wants to use a tool\n",
    "    if last_message.tool_calls:\n",
    "        # If yes -> go to tool_node to execute the tool\n",
    "        return \"tool_node\"\n",
    "    \n",
    "    # If no tool calls -> we're done! The AI has the final answer\n",
    "    return END\n",
    "\n",
    "print(\"‚úÖ Routing logic defined\")\n",
    "print(\"üìù This decides: Should we use a tool? Or are we done?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3768e2",
   "metadata": {},
   "source": [
    "## Step 6: Build and Compile the Agent\n",
    "\n",
    "Now we assemble everything into a LangGraph agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab415c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent compiled successfully!\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# BUILD THE AGENT (Putting It All Together)\n",
    "# ========================================\n",
    "# This is where we create the workflow graph!\n",
    "\n",
    "# 1. Create a graph builder with our state type\n",
    "agent_builder = StateGraph(MessagesState)\n",
    "\n",
    "# 2. Add nodes (the things that do work)\n",
    "agent_builder.add_node(\"llm_call\", llm_call)    # Node: Call the AI\n",
    "agent_builder.add_node(\"tool_node\", tool_node)  # Node: Execute tools\n",
    "\n",
    "# 3. Add edges (the connections between nodes)\n",
    "agent_builder.add_edge(START, \"llm_call\")  # Start -> Always go to llm_call first\n",
    "\n",
    "# 4. Add conditional edge (decision point)\n",
    "agent_builder.add_conditional_edges(\n",
    "    \"llm_call\",           # From: llm_call node\n",
    "    should_continue,      # Use this function to decide\n",
    "    [\"tool_node\", END]    # Possible destinations\n",
    ")\n",
    "\n",
    "agent_builder.add_edge(\"tool_node\", \"llm_call\")  # After using a tool, go back to AI\n",
    "\n",
    "# 5. Compile the graph into an executable agent\n",
    "agent = agent_builder.compile()\n",
    "\n",
    "print(\"‚úÖ Agent compiled successfully!\")\n",
    "print(\"üìù Flow: START ‚Üí llm_call ‚Üí [tool_node ‚Üí llm_call] ‚Üí END\")\n",
    "print(\"üí° The agent will loop between AI and tools until done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1108f63",
   "metadata": {},
   "source": [
    "### Visualize the Agent Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbb2778e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the agent graph\n",
    "try:\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(agent.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph: {e}\")\n",
    "    print(\"\\nAgent structure:\")\n",
    "    print(\"START -> llm_call -> [tool_node OR END]\")\n",
    "    print(\"tool_node -> llm_call (loops back)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f37ae27",
   "metadata": {},
   "source": [
    "## Step 7: Test the Agent\n",
    "\n",
    "Let's run some arithmetic tasks and see how the agent works!\n",
    "\n",
    "### üîç What to Observe:\n",
    "- **User message**: The question we ask\n",
    "- **AI message**: The AI's response (may include tool calls)\n",
    "- **Tool messages**: Results from executing tools\n",
    "- **Final AI message**: The AI's final answer to the user\n",
    "\n",
    "### üí° Understanding the Flow:\n",
    "1. User asks a question\n",
    "2. AI decides if it needs to use a tool\n",
    "3. If yes: Tool executes ‚Üí Result sent back to AI ‚Üí AI formulates answer\n",
    "4. If no: AI responds directly\n",
    "\n",
    "---\n",
    "\n",
    "### Test 1: Simple Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97cbabf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 1: Add 3 and 4\n",
      "============================================================\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (530877bf-0f21-4ab3-b8f3-625c79fc65d7)\n",
      " Call ID: 530877bf-0f21-4ab3-b8f3-625c79fc65d7\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of adding 3 and 4 is 7.\n",
      "\n",
      "üìä Total LLM calls: 2\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (530877bf-0f21-4ab3-b8f3-625c79fc65d7)\n",
      " Call ID: 530877bf-0f21-4ab3-b8f3-625c79fc65d7\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of adding 3 and 4 is 7.\n",
      "\n",
      "üìä Total LLM calls: 2\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Test 1: Simple addition\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 1: Add 3 and 4\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "messages = [HumanMessage(content=\"Add 3 and 4.\")]\n",
    "result = agent.invoke({\"messages\": messages})\n",
    "\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()\n",
    "\n",
    "print(f\"\\nüìä Total LLM calls: {result.get('llm_calls', 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57454410",
   "metadata": {},
   "source": [
    "### Test 2: Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a211d77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 2: Multiply 7 by 8\n",
      "============================================================\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is 7 times 8?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (aae128d9-6a3a-433a-bd78-f64c12f303bb)\n",
      " Call ID: aae128d9-6a3a-433a-bd78-f64c12f303bb\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 8\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "56\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 7 and 8 is 56.\n",
      "\n",
      "üìä Total LLM calls: 2\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is 7 times 8?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (aae128d9-6a3a-433a-bd78-f64c12f303bb)\n",
      " Call ID: aae128d9-6a3a-433a-bd78-f64c12f303bb\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 8\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "56\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 7 and 8 is 56.\n",
      "\n",
      "üìä Total LLM calls: 2\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Multiplication\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 2: Multiply 7 by 8\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "messages = [HumanMessage(content=\"What is 7 times 8?\")]\n",
    "result = agent.invoke({\"messages\": messages})\n",
    "\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()\n",
    "\n",
    "print(f\"\\nüìä Total LLM calls: {result.get('llm_calls', 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f027bd",
   "metadata": {},
   "source": [
    "### Test 3: Multi-Step Calculation\n",
    "\n",
    "This test requires the agent to use tools multiple times!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7357a5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 3: Complex calculation\n",
      "============================================================\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 5 and 3, then multiply the result by 2.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (dabb16ab-a94c-4185-9ae1-09b39242432e)\n",
      " Call ID: dabb16ab-a94c-4185-9ae1-09b39242432e\n",
      "  Args:\n",
      "    a: 5\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "15\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The final answer is $\\boxed{15}$.\n",
      "\n",
      "üìä Total LLM calls: 2\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 5 and 3, then multiply the result by 2.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (dabb16ab-a94c-4185-9ae1-09b39242432e)\n",
      " Call ID: dabb16ab-a94c-4185-9ae1-09b39242432e\n",
      "  Args:\n",
      "    a: 5\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "15\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The final answer is $\\boxed{15}$.\n",
      "\n",
      "üìä Total LLM calls: 2\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Complex multi-step calculation\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 3: Complex calculation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "messages = [HumanMessage(content=\"Add 5 and 3, then multiply the result by 2.\")]\n",
    "result = agent.invoke({\"messages\": messages})\n",
    "\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()\n",
    "\n",
    "print(f\"\\nüìä Total LLM calls: {result.get('llm_calls', 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db4d82f",
   "metadata": {},
   "source": [
    "### Test 4: Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d94f73fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 4: Divide 100 by 4\n",
      "============================================================\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Divide 100 by 4.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  divide (9ae5e029-2c2b-4e4a-9b53-e705d1cee9da)\n",
      " Call ID: 9ae5e029-2c2b-4e4a-9b53-e705d1cee9da\n",
      "  Args:\n",
      "    a: 100\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "25.0\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of dividing 100 by 4 is 25.0.\n",
      "\n",
      "üìä Total LLM calls: 2\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Divide 100 by 4.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  divide (9ae5e029-2c2b-4e4a-9b53-e705d1cee9da)\n",
      " Call ID: 9ae5e029-2c2b-4e4a-9b53-e705d1cee9da\n",
      "  Args:\n",
      "    a: 100\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "25.0\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of dividing 100 by 4 is 25.0.\n",
      "\n",
      "üìä Total LLM calls: 2\n"
     ]
    }
   ],
   "source": [
    "# Test 4: Division\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 4: Divide 100 by 4\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "messages = [HumanMessage(content=\"Divide 100 by 4.\")]\n",
    "result = agent.invoke({\"messages\": messages})\n",
    "\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()\n",
    "\n",
    "print(f\"\\nüìä Total LLM calls: {result.get('llm_calls', 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a18b6c3",
   "metadata": {},
   "source": [
    "## üéâ Congratulations!\n",
    "\n",
    "You've successfully replicated the LangGraph quickstart tutorial using a **local model (Llama 3.2 1B via Ollama)**!\n",
    "\n",
    "### Key Differences from Original Tutorial:\n",
    "- ‚úÖ **Local Model**: Using `llama3.2:1b` instead of `anthropic:claude-sonnet-4-5`\n",
    "- ‚úÖ **No API Keys**: Everything runs locally on your machine\n",
    "- ‚úÖ **Same Functionality**: Tool calling, state management, and routing work the same way\n",
    "- ‚úÖ **Fast & Lightweight**: 1B model is quick to download and run\n",
    "\n",
    "### Other Compatible Local Models:\n",
    "- `llama3.2:3b` (better performance, slower download - 2GB)\n",
    "- `llama3.1:8b` (even better, larger - 4.7GB)\n",
    "- `mistral` (7B, good tool calling - 4.1GB)\n",
    "- `qwen2.5:7b` (Qwen 7B+ supports tools - 4.7GB)\n",
    "\n",
    "### To Switch Models:\n",
    "Just change the model name in cell 5:\n",
    "```python\n",
    "model = ChatOllama(model=\"llama3.2:3b\", temperature=0)\n",
    "```\n",
    "\n",
    "Then run: `ollama pull <model-name>` in terminal first.\n",
    "\n",
    "### Next Steps:\n",
    "- Experiment with different models\n",
    "- Add more complex tools\n",
    "- Build multi-agent systems\n",
    "- Explore LangGraph's advanced features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f85505",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Exercises for Students\n",
    "\n",
    "Now that you understand how this works, try these challenges:\n",
    "\n",
    "### Exercise 1: Add a New Tool\n",
    "Create a new tool called `power` that raises `a` to the power of `b`.\n",
    "- Add the `@tool` decorator\n",
    "- Include it in the `tools` list\n",
    "- Test it with: \"What is 2 to the power of 8?\"\n",
    "\n",
    "### Exercise 2: Modify the System Message\n",
    "Change the system message in the `llm_call` function to make the agent respond in a different style (e.g., \"like a pirate\" or \"very formally\").\n",
    "\n",
    "### Exercise 3: Track More State\n",
    "Add a new field to `MessagesState` to track the number of tools used. Update `tool_node` to increment this counter.\n",
    "\n",
    "### Exercise 4: Create Your Own Agent\n",
    "Think of a different domain (e.g., string manipulation, data analysis) and create tools for it. Build a new agent using the same pattern!\n",
    "\n",
    "### Exercise 5: Handle Edge Cases\n",
    "What happens if you try to divide by zero? Modify the `divide` tool to handle this error gracefully.\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "- **LangGraph Documentation**: https://docs.langchain.com/oss/python/langgraph/\n",
    "- **LangChain Tools**: https://python.langchain.com/docs/modules/tools/\n",
    "- **Ollama Models**: https://ollama.ai/library\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
