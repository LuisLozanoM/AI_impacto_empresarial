{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a2c02d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf20c86ec0e84b7e840a6bd2458aff61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\L03055876\\Desktop\\AI_impacto_empresarial\\ai_ml_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\L03055876\\.cache\\huggingface\\hub\\datasets--mnist. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0128cf2caf7c4d5b9f963a5444d4a60d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/15.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a948ef5f1844cadb3a8444b33e44d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/2.60M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad59b02f76c4ab0866e70c8b1141c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/60000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8fec77c275548f0a43700d42a402bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "mnist = load_dataset(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6bdeee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+trwt4W1TxfrcOl6VDvlc5eRvuRL3Zj2A/wD1V0Xj74YXvgeKG5S+TU7NmMU00MRUW8oCnY/JAzu455x0FcHVnTrC51XUrbT7OMyXNzKsUaDuxOBXrmveMYfhfpk/gfwsG/tCJ1e/1TOC8pwWVR2GMLnIxg9+aboGsX/jvwD8SLrX7tpXjitrqPaAio6iTGAOMHYo98eteOV0ngC8t7D4gaDd3cyQ28V5G0kjnCqM9SfSvRvFXwjgttb1LxDr/i6xs9Hup3uY5QpeaYMxbaqjAJwe2fpXDeJ/Fdk+nHw34Whez8PKweTzADNeSA/6yRuuPReAPT046iiiiv/Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABIUlEQVR4AWIYBMB4/t/5RjjcYfDuz58/b7FLmj3+++f9yz+WbJjSXDYP/vz9cyrkz98qiCQThAKTMw/IMDAwGPEcZNAF85Eljb0ZGQ+VMr44P4mJESKJACC3bObxrhRlYPj7Gc3Bakv/vrwQAlH7989SCAMK2Df9+eAuDLKTgYHh75/DUGEIsPzzxx7CwiJ57O8+uBzD/79HwByoV3wM/m8C88HEv/8XwDQUhP55JgllMrC3/93FA+OAQOif+yAKhNmb/zx0BzHgOPTPRCjbYOmftVAmjAIs7O9DCLPo3d9FEBaCDP3zc5KBbOimh3/vL7dACENYoX/+/Hl6/c+fP0eaIALIpMzxP3/+/vnzEmYzshwDg2TDn79/elVRBQeCBwCscG5E1y1scgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist[\"train\"][\"image\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "171e71f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist[\"train\"][\"label\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e10b4834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from genaibook.core import show_images\n",
    "\n",
    "show_images(mnist[\"train\"][\"image\"][:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73a92ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "def mnist_to_tensor(samples):\n",
    "    t = transforms.ToTensor()\n",
    "    samples[\"image\"] = [t(img) for img in samples[\"image\"]]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4dc3b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = mnist.with_transform(mnist_to_tensor)\n",
    "mnist[\"train\"] = mnist[\"train\"].shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20690ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(1.))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = mnist[\"train\"][\"image\"][0]\n",
    "x.min(), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "028ea874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_images(mnist[\"train\"][\"image\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2efa807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "bs = 64\n",
    "train_dataloader = DataLoader(mnist[\"train\"][\"image\"], batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edd09e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "def conv_block(in_channels, out_channels, kernel_size=4, stride=2, padding=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(\n",
    "            in_channels, \n",
    "            out_channels, \n",
    "            kernel_size=kernel_size, \n",
    "            stride=stride, \n",
    "            padding=padding),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cc429fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = conv_block(in_channels, 128)\n",
    "        self.conv2 = conv_block(128, 256)\n",
    "        self.conv3 = conv_block(256, 512)\n",
    "        self.conv4 = conv_block(512, 1024)\n",
    "        self.linear = nn.Linear(1024, 16)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.linear(x.flatten(start_dim=1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f306a60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist[\"train\"][\"image\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5910456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_channels = 1\n",
    "x = mnist[\"train\"][\"image\"][0][None, :]\n",
    "encoder = Encoder(in_channels).eval()\n",
    "\n",
    "encoded = encoder(x)\n",
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2494dbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0266,  0.0265,  0.0059, -0.0245, -0.0143, -0.0100, -0.0154, -0.0087,\n",
       "         -0.0046, -0.0299,  0.0077, -0.0306, -0.0233, -0.0101, -0.0042, -0.0229]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53e2a316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64, 16]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "encoded = Encoder(in_channels=1)(batch)\n",
    "batch.shape, encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5255079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_transpose_block(\n",
    "    in_channels,\n",
    "    out_channels,\n",
    "    kernel_size=3,\n",
    "    stride=2,\n",
    "    padding=1,\n",
    "    output_padding=0,\n",
    "    with_act=True,\n",
    "):\n",
    "    modules = [\n",
    "        nn.ConvTranspose2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            output_padding=output_padding,\n",
    "        ),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "    ]\n",
    "    if with_act:\n",
    "        modules.append(nn.BatchNorm2d(out_channels))\n",
    "        modules.append(nn.ReLU())\n",
    "    return nn.Sequential(*modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db390aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(16, 1024*4*4)\n",
    "        self.t_conv1 = conv_transpose_block(1024, 512)\n",
    "        self.t_conv2 = conv_transpose_block(512, 256, output_padding=1)\n",
    "        self.t_conv3 = conv_transpose_block(256, out_channels, output_padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        x = self.linear(x)\n",
    "        x = x.reshape((bs, 1024, 4, 4))\n",
    "        x = self.t_conv1(x)\n",
    "        x = self.t_conv2(x)\n",
    "        x = self.t_conv3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9b36436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_batch = Decoder(x.shape[0])(encoded)\n",
    "decoded_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "273fc7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(in_channels)\n",
    "        self.decoder = Decoder(in_channels)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.decode(self.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7848732",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f747e6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 128, 14, 14]           2,176\n",
      "       BatchNorm2d-2          [-1, 128, 14, 14]             256\n",
      "              ReLU-3          [-1, 128, 14, 14]               0\n",
      "            Conv2d-4            [-1, 256, 7, 7]         524,544\n",
      "       BatchNorm2d-5            [-1, 256, 7, 7]             512\n",
      "              ReLU-6            [-1, 256, 7, 7]               0\n",
      "            Conv2d-7            [-1, 512, 3, 3]       2,097,664\n",
      "       BatchNorm2d-8            [-1, 512, 3, 3]           1,024\n",
      "              ReLU-9            [-1, 512, 3, 3]               0\n",
      "           Conv2d-10           [-1, 1024, 1, 1]       8,389,632\n",
      "      BatchNorm2d-11           [-1, 1024, 1, 1]           2,048\n",
      "             ReLU-12           [-1, 1024, 1, 1]               0\n",
      "           Linear-13                   [-1, 16]          16,400\n",
      "          Encoder-14                   [-1, 16]               0\n",
      "           Linear-15                [-1, 16384]         278,528\n",
      "  ConvTranspose2d-16            [-1, 512, 7, 7]       4,719,104\n",
      "      BatchNorm2d-17            [-1, 512, 7, 7]           1,024\n",
      "      BatchNorm2d-18            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-19            [-1, 512, 7, 7]               0\n",
      "  ConvTranspose2d-20          [-1, 256, 14, 14]       1,179,904\n",
      "      BatchNorm2d-21          [-1, 256, 14, 14]             512\n",
      "      BatchNorm2d-22          [-1, 256, 14, 14]             512\n",
      "             ReLU-23          [-1, 256, 14, 14]               0\n",
      "  ConvTranspose2d-24            [-1, 1, 28, 28]           2,305\n",
      "      BatchNorm2d-25            [-1, 1, 28, 28]               2\n",
      "      BatchNorm2d-26            [-1, 1, 28, 28]               2\n",
      "             ReLU-27            [-1, 1, 28, 28]               0\n",
      "          Decoder-28            [-1, 1, 28, 28]               0\n",
      "================================================================\n",
      "Total params: 17,217,173\n",
      "Trainable params: 17,217,173\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 3.44\n",
      "Params size (MB): 65.68\n",
      "Estimated Total Size (MB): 69.12\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "\n",
    "torchsummary.summary(model, input_size=(1, 28, 28), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef991e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from genaibook.core import get_device\n",
    "\n",
    "get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0425a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8918f5c15362454d879026fe1ae74264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cde2d84b7004581b96053f66e4c0275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.nn import functional as F\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from genaibook.core import get_device\n",
    "\n",
    "num_epochs = 10\n",
    "lr = 1e-4\n",
    "\n",
    "device = get_device() #\"mps\"\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, eps=1e-5)\n",
    "\n",
    "losses = []\n",
    "for _ in (progress := trange(num_epochs, desc = \"Training\")):\n",
    "    for _, batch in (\n",
    "        inner := tqdm(enumerate(train_dataloader), \n",
    "                      total=len(train_dataloader))\n",
    "    ):\n",
    "        batch = batch.to(device)\n",
    "        preds = model(batch)\n",
    "        loss = F.mse_loss(preds, batch)\n",
    "        inner.set_postfix(loss=f\"{loss.cpu().item():.3f}\")\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    progress.set_postfix(epoch_loss=f\"{loss.cpu().item():.3f}\", lr=f\"{lr:.0e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbe1f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
